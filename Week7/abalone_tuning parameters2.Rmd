---
title: "Untitled"
author: "Raghu"
date: "October 31, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

To clean the Environment
```{r}
rm(list = ls(all=TRUE))
```

TO make sure that the files we read exist in the workig directory or not
```{r}
setwd("C:/Users/RaghuTeja/Desktop/intern/")
```
TO read the data 
```{r}
mydata <- read.table("abalone.txt", header=FALSE, sep=",")
#mydata<-mydata[-2052,]
```
TO know the first 6 rows of the dataset
```{r}
head(mydata)
```
To know the Last 6 rows in the data
```{r}
tail(mydata)
```
To know the structure of the data.
```{r}
str(mydata)
```
To check for any NA values in the entire dataset
```{r}
sum(is.na(mydata))
```
To find the detailed information of each any every attribute.
```{r}
summary(mydata)
```
To find the number of rows with each class
```{r}
table(mydata$V1)
```

Adding 1.5 to the entire coloumn(V9) as mentioned in description, for age of the abalone
```{r}
mydata$V9<-mydata$V9+1.5
```
Using library dummies as we have one attribute with 3 classes.
```{r}
#install.packages("dummies")
library(dummies)

```
Dummying the cloumn V1
```{r}
dummy1<-dummy(mydata$V1)
```
Dropping the column V1 as we have already dummied the column
```{r}
mydata$V1<-NULL
```
to check the class of the dummied variable
```{r}
class(dummy1)
```
As the class of the dummy is in matrix we change to dataframe
```{r}
dummy1<-as.data.frame(dummy1)
```
Adding the dummy columns to mydata
```{r}
mydata<-cbind(dummy1,mydata)
```

Target V9 is stored in the target variable for standardizing the entire data
```{r}
target<-mydata$V9
mydata$V9<-NULL
```
Standardizing the data using scale function
```{r}
dim(mydata)
mydata<-scale(mydata[,1:10], center = TRUE, scale = TRUE)
class(mydata)#mydata is in matrix format
mydata<-as.data.frame(mydata)#so changing it into dataframe
mydata<-cbind(mydata,target)#adding the target back to the data
str(mydata)
```
Diving the data into test and train so as to run the model and predict the best model
```{r}
set.seed(100)

# the "sample()" function helps us to randomly sample 70% of the row indices of the dataset

train_rows <- sample(x = 1:nrow(mydata), size = 0.7*nrow(mydata))

# We use the above indices to subset the train and test sets from the data

train_data <- mydata[train_rows, ]

test_data <- mydata[-train_rows, ]

```

```{r}
mae <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(abs(error))
  
}

mse <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(error^2)
  
}
rmse <- function(actual, predicted){
  
  error <- actual - predicted
  
  sqrt(mean(error^2))
  
}

mape <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(abs(error/actual))*100
  
}


```
#Neural
```{r}
std_method <- preProcess(train_data[,!names(train_data) %in% c("target")],method = c("center","scale"))
train_data[,!names(train_data) %in% c("target")] <- predict(object = std_method,newdata = train_data[,!names(train_data) %in% c("target")])
test_data[,!names(test_data) %in% c("target")] <- predict(object = std_method,newdata = test_data[,!names(test_data) %in% c("target")])
train.x<- data.matrix(train_data[,!names(train_data)  %in% c("target")])
train.y <-train_data$target
test.x<-data.matrix(test_data[,!names(test_data) %in% c("target")])
test.y <-test_data$target
```

```{r}
library(mxnet)
mx.set.seed(0)
Sys.time()-> start
model_reg <-mx.mlp(train.x, train.y, hidden_node=c(15), out_node=1, activation="tanh", out_activation="rmse",
                   num.round=20, array.batch.size=500, learning.rate=0.09, momentum=0.8,
                   eval.metric=mx.metric.mae)
Sys.time()->end
paste(end-start)
preds = predict(model_reg, test.x)

preds=t(preds)
#install.packages("DMwR")
library(DMwR)
regr.eval(preds,test.y)
summary(model_reg)
```
#GBM
```{r}
library(gbm)

model_gbm <- gbm(target ~ . , cv.folds = 8, interaction.depth = 3, 
                 shrinkage = 0.005, distribution= "gaussian",
                 data = train_data, n.trees = 1600)

gbm.perf(model_gbm)
#on train data
pred <- predict(model_gbm, train_data[, !(names(train_data) %in% c("target"))])

mae(train_data[, "target"], pred)

mse(train_data[, "target"], pred)

rmse(train_data[, "target"], pred)

regr.eval(train_data$target, pred)
#ON test data
pred <- predict(model_gbm, test_data[, !(names(test_data) %in% c("target"))])

mae(test_data[, "target"], pred)

mse(test_data[, "target"], pred)

rmse(test_data[, "target"], pred)

regr.eval(test_data$Target, pred)


```
#Bagging
```{r}
str(train)

library(ipred)
set.seed(1234)

model_tree_bag <- bagging(target ~ . , data=train_data, control = rpart.control(cp = 0.01, xval = 10))
#ON train data
pred <- predict(model_tree_bag, train_data[, !(names(train_data) %in% c("target"))])

mae(train_data[, "target"], pred)

mse(train_data[, "target"], pred)

rmse(train_data[, "target"], pred)

regr.eval(train_data$target, pred)

#ON test data
pred <- predict(model_tree_bag, test_data[, !(names(test_data) %in% c("target"))])

mae(test_data[, "target"], pred)

mse(test_data[, "target"], pred)

rmse(test_data[, "target"], pred)

regr.eval(test_data$target, pred)

```
