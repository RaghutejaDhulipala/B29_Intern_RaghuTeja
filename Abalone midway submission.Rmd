---
title: "Abalone Midway Submission"
author: "Raghu"
date: "October 2, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

To clean the Environment
```{r}
rm(list = ls(all=TRUE))
```

TO make sure that the files we read exist in the workig directory or not
```{r}
setwd("C:/Users/RaghuTeja/Desktop/intern/")
```
TO read the data 
```{r}
mydata <- read.table("abalone.txt", header=FALSE, sep=",")
```
TO know the first 6 rows of the dataset
```{r}
head(mydata)
```
To know the Last 6 rows in the data
```{r}
tail(mydata)
```
To know the structure of the data.
```{r}
str(mydata)
```
To check for any NA values in the entire dataset
```{r}
sum(is.na(mydata))
```
To find the detailed information of each any every attribute.
```{r}
summary(mydata)
```
To find the number of rows with each class
```{r}
table(mydata$V1)
```

Adding 1.5 to the entire coloumn(V9) as mentioned in description, for age of the abalone
```{r}
mydata$V9<-mydata$V9+1.5
```
Using library dummies as we have one attribute with 3 classes.
```{r}
#install.packages("dummies")
library(dummies)

```
Dummying the cloumn V1
```{r}
dummy1<-dummy(mydata$V1)
```
Dropping the column V1 as we have already dummied the column
```{r}
mydata$V1<-NULL
```
to check the class of the dummied variable
```{r}
class(dummy1)
```
As the class of the dummy is in matrix we change to dataframe
```{r}
dummy1<-as.data.frame(dummy1)
```
Adding the dummy columns to mydata
```{r}
mydata<-cbind(dummy1,mydata)
```


## Correlation Plot

* Let's have a look at the various correlations between the variables in the dataset

```{r fig.height= 8, fig.width = 9}

library(corrplot)

corrplot(cor(mydata), method = "number")

```

## Scatter Plots

* A few bi-variate relationships are plotted below, but you are encouraged to explore the dataset in more detail

```{r fig.height= 8, fig.width = 9}

par(mfrow = c(2,2))

plot(mydata$V9, mydata$V2, xlab = "Number of Rings", ylab = "Length", main = "Number of Rings Vs Length")

plot(mydata$V9, mydata$V3, xlab = "Number of Rings", ylab = "Diameter", main = "Number of Rings Vs Diameter")

plot(mydata$V9, mydata$V4, xlab = "Number of Rings", ylab = "Height", main = "Number of Rings Vs Height")

plot(mydata$V9, mydata$V5, xlab = "Number of Rings", ylab = "Whole Weight", main = "Number of Rings Vs Whole weight")

plot(mydata$V9, mydata$V6, xlab = "Number of Rings", ylab = "Shucked weight", main = "Number of Rings Vs Shucked Weight")

plot(mydata$V9, mydata$V7, xlab = "Number of Rings", ylab = "Viscera Weight", main = "Number of Rings Vs Viscera Weight")

plot(mydata$V9, mydata$V8, xlab = "Number of Rings", ylab = "Shell Weight", main = "Number of Rings Vs Shell Weight")
```

Target V9 is stored in the target variable for standardizing the entire data
```{r}
target<-mydata$V9
mydata$V9<-NULL
```
Standardizing the data using scale function
```{r}
dim(mydata)
mydata<-scale(mydata[,1:10], center = TRUE, scale = TRUE)
class(mydata)#mydata is in matrix format
mydata<-as.data.frame(mydata)#so changing it into dataframe
mydata<-cbind(mydata,target)#adding the target back to the data
str(mydata)
```
Diving the data into test and train so as to run the model and predict the best model
```{r}
set.seed(100)

# the "sample()" function helps us to randomly sample 70% of the row indices of the dataset

train_rows <- sample(x = 1:nrow(mydata), size = 0.7*nrow(mydata))

# We use the above indices to subset the train and test sets from the data

train_data <- mydata[train_rows, ]

test_data <- mydata[-train_rows, ]

```
Runing the linear model on the entire data initially. 
```{r}
model1 <- lm(formula = target ~., data = train_data)
summary(model1)
```
Plotting the linear model on the train data.
```{r}
par(mfrow = c(2,2)) 
plot(model1)
```
Predicting the model on the test data
```{r}
preds <- predict(model1, test_data[, !(names(test_data) %in% c("target"))])
```

```{r}
mae <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(abs(error))
  
}

mse <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(error^2)
  
}
rmse <- function(actual, predicted){
  
  error <- actual - predicted
  
  sqrt(mean(error^2))
  
}
mape <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(abs(error/actual))*100
  
}

mae(test_data[, "target"], preds)

mse(test_data[, "target"], preds)

rmse(test_data[, "target"], preds)

mape(test_data[, "target"], preds)
```
Dimentionality reduction.
#Step AIC

```{r}
library(MASS)
model_aic <- stepAIC(model1, direction = "both")

summary(model_aic)

par(mfrow = c(2,2))

plot(model_aic)

```
#VIF
```{r}
#install.packages("car")
library(car)

vif(model1)

vif(model_aic)

```

By the VIF values checking the correlation between V5 &V6
```{r}
library(corrplot)
corrplot(cor(mydata))
cor(mydata$V5,mydata$V6)
mydata$V5<-NULL
train_data$V5<-NULL
test_data$V5<-NULL
str(train_data)
```

```{r}
#Without V5
model2 <- lm(formula = target ~., data = train_data)
summary(model2)

```

```{r}
#pred<-predict(model2,test_data)
model_aic_2 <- stepAIC(model2, direction = "both")

summary(model_aic_2)

par(mfrow = c(2,2))

plot(model_aic_2)

vif(model_aic_2)

```


```{r}
cor(train_data$V3, train_data$V8)
#model3<-lm(Target ~ V1 + V3 + V4 + V6 + V8, train_data)
model3<-lm(formula = target ~., data=train_data)
summary(model3)

```

```{r}
model_aic3<-stepAIC(model3, direction = "both")
summary(model_aic3)

```

```{r}
mae <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(abs(error))
  
}

mse <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(error^2)
  
}
rmse <- function(actual, predicted){
  
  error <- actual - predicted
  
  sqrt(mean(error^2))
  
}
```

```{r}
preds <- predict(model_aic_2, test_data[, !(names(test_data) %in% c("target"))])

mae(test_data[, "target"], preds)

mse(test_data[, "target"], preds)

rmse(test_data[, "target"], preds)

regr.eval(test_data$target, preds)
```

```{r}
preds <- predict(model_aic3, test_data[, !(names(test_data) %in% c("target"))])

mae(test_data[, "target"], preds)

mse(test_data[, "target"], preds)

rmse(test_data[, "target"], preds)

regr.eval(test_data$target, preds)

```



```{r}
plot(mydata$target,mydata$V6)
plot(mydata$target,mydata$V7)
boxplot(mydata$V6)
boxplot(mydata)

```

#Using Lasso
```{r}
library(doParallel)
library(glmnet)
registerDoParallel(10)
x=model.matrix(target~., mydata)
fit.lasso<-cv.glmnet(x,mydata$target,type.measure="mse",alpha=1,family="gaussian",nfolds=10,parallel=T)


c=coef(fit.lasso,s=fit.lasso$lambda.1se)
  inds<-which(c!=0)
  imp_att<-row.names(c)[inds]
  imp_att<-imp_att[-c(grep("Intercept",imp_att))]
  imp_att

```


```{r}
mydata$V1F<-NULL
mydata$V1M<-NULL
mydata$V2<-NULL
mydata$V7<-NULL
mydata$target<-NULL
```


```{r}
class(mydata)
View(mydata)
```

```{r}
mydata<-cbind(mydata,target)
```
```{r}
model1 <- lm(formula = target ~., data = train_data)
summary(model1)
```

```{r}
mae <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(abs(error))
  
}

mse <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(error^2)
  
}
rmse <- function(actual, predicted){
  
  error <- actual - predicted
  
  sqrt(mean(error^2))
  
}

mape <- function(actual, predicted){
  
  error <- actual - predicted
  
  mean(abs(error/actual))*100
  
}


```

```{r}
preds <- predict(model4, test_data[, !(names(test_data) %in% c("target"))])
```

```{r}
mae(test_data[, "target"], preds)

mse(test_data[, "target"], preds)

rmse(test_data[, "target"], preds)

```

```{r}

library(randomForest)
rf <- randomForest(target ~ ., data=train_data)

plot(rf)

importance(rf)
preds_rf <- predict(rf, test_data[, !(names(test_data) %in% c("target"))])

mae(test_data[, "target"], preds_rf)

mse(test_data[, "target"], preds_rf)

rmse(test_data[, "target"], preds_rf)

  regr.eval(test_data$target, preds_rf)
names(train_data)
```

```{r}
rf <- randomForest(target ~  V8 + V7 + V6 + V5 + V4 + V3 +V2 + V1I , data=train_data)
importance(rf)
preds_rf_imp <- predict(rf, test_data[, !(names(test_data) %in% c("Target"))])

mae(test_data[, "target"], preds_rf_imp)

mse(test_data[, "target"], preds_rf_imp)

rmse(test_data[, "target"], preds_rf_imp)

regr.eval(test_data$target, preds_rf_imp)

```
#SVM
```{r}
library(e1071)
library(caret)
model_svm <- svm(target ~ ., data = train_data, kernal = "linear")
summary(model_svm)
preds_svm <- predict(model_svm, test_data[, !(names(test_data) %in% c("target"))])

mae(test_data[, "target"], preds_svm)

mse(test_data[, "target"], preds_svm)

rmse(test_data[, "target"], preds_svm)

regr.eval(test_data$Target, preds_svm)
```
```{r}
model_svm1 <- svm(target ~ ., data = train_data, kernal = "gausspr")
summary(model_svm)
preds_svm1 <- predict(model_svm1, test_data[, !(names(test_data) %in% c("target"))])

mae(test_data[, "target"], preds_svm1)

mse(test_data[, "target"], preds_svm1)

rmse(test_data[, "target"], preds_svm1)

regr.eval(test_data$Target, preds_svm1)
```

CART
```{r}
library(rpart)

model_dt <- rpart(target ~ . , train_data)
pred_dt <- predict(model_dt, test_data[, !(names(test_data) %in% c("target"))])

mae(test_data[, "target"], pred_dt)

mse(test_data[, "target"], pred_dt)

rmse(test_data[, "target"], pred_dt)

regr.eval(test_data$Target, pred_dt)


```


